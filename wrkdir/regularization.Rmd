---
title: "Hands on with Regularization and Tree based Model Ensemble"
output: html_notebook
---


```{r}
housing_df = read.csv("housing.csv")[,-1]
## first column is Id so it can be removed
```

## Section 1. Data Cleaning

__1.__ Take a summary of the data and explore the result. How many categorical and numerical variables are
there in the dataset?

```{r}
summary(housing_df)
```
```{r}
length(housing_df[,sapply(housing_df, is.character) == TRUE]) ## Number of categorical variables
length(housing_df[,sapply(housing_df, is.numeric) == TRUE]) ## Number of numerical variables
```

__2.__ (1pt) Which columns have missing values and what percentage of those columns have NAs? (Note.
You can use colMeans(is.na(your data frame)) to find the percentage of NAs in each column).
```{r}
missing_vals_columns = which(colSums(is.na(housing_df)) > 0)
sort(colSums(sapply(housing_df[missing_vals_columns], is.na)), decreasing = TRUE)
```
The above columns have missing values
```{r}
means = colMeans(sapply(housing_df[missing_vals_columns], is.na))
newmeans = as.numeric(sprintf("%2.3f", means)) * 100
names(newmeans) = names(means)
sort(newmeans, decreasing = TRUE)
```
The above are the % NAs in each column with NAs

__3.__ Is there any obvious outlier in the SalePrice? If so, remove them
```{r}
## Before transformation
str(housing_df$SalePrice)
first_quant = quantile(housing_df$SalePrice)[2]
third_quant = quantile(housing_df$SalePrice)[4]
iqr = third_quant - first_quant
iqr_index = (housing_df$SalePrice > first_quant - 1.5*iqr & housing_df$SalePrice < third_quant + 1.5*iqr)
housing_df = housing_df[iqr_index, ]
## After transformation
str(housing_df$SalePrice)
```

__4.__ (2pt)Read the data description carefully. For some of the variables, such as PoolQC, FirePlaceQU,
Fence, etc. NA means not applicable rather than missing at random. For instance, a house that does
not have a pool gets NA for PoolQC. For those variables for which NA means not applicable, you
can replace NA with zero ( if that variable is numeric) or replace it with a new category/level, for
instance, “notApplicable” if that variable is categorical.

```{r}
# Cleaning categorical variables
cat_columns = c("Alley","BsmtQual","BsmtCond","BsmtExposure","BsmtFinType1","BsmtFinType2","FireplaceQu","GarageType","GarageFinish","GarageQual","GarageCond","PoolQC","Fence","MiscFeature")
new_columns = lapply(cat_columns, function(x){
  housing_df[is.na(housing_df[,x]),x] <<- "notApplicable"
})

# Cleaning numerical variables
num_columns = (sapply(housing_df, is.numeric) == TRUE) & (colSums(is.na(housing_df)) > 0)
new_columns = lapply(names(housing_df[,num_columns]), function(x){
  housing_df[is.na(housing_df[,x]),x] <<- 0
})
```

__5.__ (1pt) After replacing not applicable NAs with appropriate values, find out which columns still
have NAs and what percentage of each column is missing.

```{r}
missing_vals_columns = which(colSums(is.na(housing_df)) > 0)
means = colMeans(sapply(housing_df[missing_vals_columns], is.na))
newmeans = as.numeric(sprintf("%2.3f", means)) * 100
names(newmeans) = names(means)
sort(newmeans, decreasing = TRUE)
```

__6.__ (1pt) what percentage of rows in the dataset have one or more missing values? Use
“complete.cases” function to answer this question.

```{r}

```

